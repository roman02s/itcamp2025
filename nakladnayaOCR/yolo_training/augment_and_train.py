#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ YOLO —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 100% –∫–∞—á–µ—Å—Ç–≤–∞
"""

import os
import json
import random
import shutil
from pathlib import Path
import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import yaml
from ultralytics import YOLO
import torch

class DataAugmentator:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, source_dir: str, output_dir: str):
        self.source_dir = Path(source_dir)
        self.output_dir = Path(output_dir)
        self.classes = [
            "delivery-date",    # 0
            "order-date",       # 1  
            "carrier",          # 2
            "recipient",        # 3
            "payload",          # 4
            "price",            # 5
            "address"           # 6
        ]
        
    def create_augmented_dataset(self, num_augmentations=50):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print(f"–°–æ–∑–¥–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å {num_augmentations} –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏...")
        
        # –û—á–∏—â–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        if self.output_dir.exists():
            shutil.rmtree(self.output_dir)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        for split in ['train', 'val']:
            (self.output_dir / split / 'images').mkdir(parents=True, exist_ok=True)
            (self.output_dir / split / 'labels').mkdir(parents=True, exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        annotation_file = self.source_dir / 'annotated_data.json'
        with open(annotation_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        image_path = self.source_dir / data['key']
        image = cv2.imread(str(image_path))
        height, width = image.shape[:2]
        
        # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (train)
        self._save_sample(image, data['boxes'], 0, 'train', width, height)
        
        # –°–æ–∑–¥–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        for i in range(1, num_augmentations + 1):
            aug_image, aug_boxes = self._augment_image_and_boxes(
                image.copy(), data['boxes'], width, height
            )
            
            # 80% –≤ train, 20% –≤ val
            split = 'train' if i <= num_augmentations * 0.8 else 'val'
            self._save_sample(aug_image, aug_boxes, i, split, width, height)
        
        # –°–æ–∑–¥–∞–µ–º dataset.yaml
        self._create_dataset_yaml()
        
        print(f"–°–æ–∑–¥–∞–Ω–æ {num_augmentations + 1} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        train_count = len(list((self.output_dir / 'train' / 'images').glob('*.png')))
        val_count = len(list((self.output_dir / 'val' / 'images').glob('*.png')))
        print(f"Train: {train_count}, Val: {val_count}")
    
    def _augment_image_and_boxes(self, image, boxes, orig_width, orig_height):
        """–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –±–æ–∫—Å–æ–≤"""
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        
        # –°–ª—É—á–∞–π–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        augmentations = []
        
        # 1. –ò–∑–º–µ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏ (–±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ)
        if random.random() < 0.5:
            factor = random.uniform(0.9, 1.1)
            enhancer = ImageEnhance.Brightness(pil_image)
            pil_image = enhancer.enhance(factor)
            augmentations.append(f"brightness_{factor:.2f}")

        # 2. –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ (–±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ)
        if random.random() < 0.5:
            factor = random.uniform(0.9, 1.1)
            enhancer = ImageEnhance.Contrast(pil_image)
            pil_image = enhancer.enhance(factor)
            augmentations.append(f"contrast_{factor:.2f}")

        # 3. –û—á–µ–Ω—å –ª–µ–≥–∫–æ–µ —Ä–∞–∑–º—ã—Ç–∏–µ
        if random.random() < 0.2:
            radius = random.uniform(0.3, 0.8)
            pil_image = pil_image.filter(ImageFilter.GaussianBlur(radius=radius))
            augmentations.append(f"blur_{radius:.2f}")

        # 4. –®—É–º (–º–µ–Ω—å—à–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏)
        if random.random() < 0.3:
            np_image = np.array(pil_image)
            noise = np.random.normal(0, random.uniform(3, 8), np_image.shape).astype(np.uint8)
            np_image = np.clip(np_image.astype(np.int16) + noise, 0, 255).astype(np.uint8)
            pil_image = Image.fromarray(np_image)
            augmentations.append("noise")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ OpenCV
        aug_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

        # 5. –õ–µ–≥–∫–æ–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ —Å–¥–≤–∏–≥)
        if random.random() < 0.4:
            h, w = aug_image.shape[:2]

            # –ú–∞–ª–µ–Ω—å–∫–∏–π —Å–ª—É—á–∞–π–Ω—ã–π —Å–¥–≤–∏–≥
            max_shift = 5  # –ø–∏–∫—Å–µ–ª–µ–π (—É–º–µ–Ω—å—à–∏–ª–∏)
            shift_x = random.randint(-max_shift, max_shift)
            shift_y = random.randint(-max_shift, max_shift)

            # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
            M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])
            aug_image = cv2.warpAffine(aug_image, M, (w, h),
                                     borderMode=cv2.BORDER_REFLECT)

            # –°–¥–≤–∏–≥–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –±–æ–∫—Å–æ–≤
            boxes = [self._shift_box(box, shift_x, shift_y, w, h) for box in boxes]
            augmentations.append(f"shift_{shift_x}_{shift_y}")
        
        return aug_image, boxes

    def _shift_box(self, box, shift_x, shift_y, img_w, img_h):
        """–°–¥–≤–∏–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –±–æ–∫—Å–∞"""
        x = float(box['x']) + shift_x
        y = float(box['y']) + shift_y
        width = float(box['width'])
        height = float(box['height'])

        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –±–æ–∫—Å –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        x = max(0, min(x, img_w - width))
        y = max(0, min(y, img_h - height))
        width = min(width, img_w - x)
        height = min(height, img_h - y)

        return {
            'id': box['id'],
            'label': box['label'],
            'x': str(x),
            'y': str(y),
            'width': str(width),
            'height': str(height),
            'confidence': box.get('confidence', 1.0)
        }

    def _scale_box(self, box, scale, orig_w, orig_h):
        """–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –±–æ–∫—Å–∞"""
        x = float(box['x']) * scale
        y = float(box['y']) * scale
        width = float(box['width']) * scale
        height = float(box['height']) * scale
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –±–æ–∫—Å –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        x = max(0, min(x, orig_w - width))
        y = max(0, min(y, orig_h - height))
        width = min(width, orig_w - x)
        height = min(height, orig_h - y)
        
        return {
            'id': box['id'],
            'label': box['label'],
            'x': str(x),
            'y': str(y),
            'width': str(width),
            'height': str(height),
            'confidence': box.get('confidence')
        }
    
    def _save_sample(self, image, boxes, index, split, orig_width, orig_height):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_filename = f"sample_{index:03d}.png"
        image_path = self.output_dir / split / 'images' / image_filename
        cv2.imwrite(str(image_path), image)
        
        # –°–æ–∑–¥–∞–µ–º YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        yolo_annotations = []
        for box in boxes:
            yolo_line = self._convert_box_to_yolo(box, orig_width, orig_height)
            if yolo_line:
                yolo_annotations.append(yolo_line)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        label_filename = f"sample_{index:03d}.txt"
        label_path = self.output_dir / split / 'labels' / label_filename
        
        with open(label_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(yolo_annotations))
    
    def _convert_box_to_yolo(self, box, image_width, image_height):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –±–æ–∫—Å–∞ –≤ —Ñ–æ—Ä–º–∞—Ç YOLO"""
        x = float(box['x'])
        y = float(box['y'])
        width = float(box['width'])
        height = float(box['height'])
        
        # –¶–µ–Ω—Ç—Ä –±–æ–∫—Å–∞
        center_x = x + width / 2
        center_y = y + height / 2
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        norm_center_x = center_x / image_width
        norm_center_y = center_y / image_height
        norm_width = width / image_width
        norm_height = height / image_height
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
        norm_center_x = max(0, min(1, norm_center_x))
        norm_center_y = max(0, min(1, norm_center_y))
        norm_width = max(0, min(1, norm_width))
        norm_height = max(0, min(1, norm_height))
        
        class_name = box['label']
        if class_name not in self.classes:
            return None
        
        class_idx = self.classes.index(class_name)
        return f"{class_idx} {norm_center_x:.6f} {norm_center_y:.6f} {norm_width:.6f} {norm_height:.6f}"
    
    def _create_dataset_yaml(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        dataset_config = {
            'path': str(self.output_dir.absolute()),
            'train': 'train/images',
            'val': 'val/images',
            'nc': len(self.classes),
            'names': {i: name for i, name in enumerate(self.classes)}
        }
        
        yaml_path = self.output_dir / 'dataset.yaml'
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True)

class EnhancedYoloTrainer:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä YOLO –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, dataset_path: str, model_output_dir: str):
        self.dataset_path = Path(dataset_path)
        self.model_output_dir = Path(model_output_dir)
        self.model_output_dir.mkdir(parents=True, exist_ok=True)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
    def train_overfit_model(self):
        """–û–±—É—á–µ–Ω–∏–µ —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º –¥–ª—è 100% –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö"""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º YOLOv8s –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        model = YOLO('yolov8s.pt')
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        train_args = {
            'data': str(self.dataset_path / 'dataset.yaml'),
            'epochs': 300,           # –ú–Ω–æ–≥–æ —ç–ø–æ—Ö
            'batch': 8,              # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –±–∞—Ç—á –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            'imgsz': 640,
            'device': self.device,
            'project': str(self.model_output_dir),
            'name': 'overfit_model',
            'save_period': 50,
            'patience': 0,           # –û—Ç–∫–ª—é—á–∞–µ–º early stopping
            'save': True,
            'cache': True,
            'workers': 2,
            'verbose': True,
            'exist_ok': True,
            
            # –û—Ç–∫–ª—é—á–∞–µ–º –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
            'hsv_h': 0.0,
            'hsv_s': 0.0,
            'hsv_v': 0.0,
            'degrees': 0.0,
            'translate': 0.0,
            'scale': 0.0,
            'shear': 0.0,
            'perspective': 0.0,
            'flipud': 0.0,
            'fliplr': 0.0,
            'mosaic': 0.0,          # –û—Ç–∫–ª—é—á–∞–µ–º –º–æ–∑–∞–∏–∫—É
            'mixup': 0.0,
            'copy_paste': 0.0,
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —Å–ª–∏–ø–∞–Ω–∏—è)
            'lr0': 0.0005,          # –ï—â–µ –º–µ–Ω—å—à–∏–π learning rate
            'lrf': 0.0005,          # –§–∏–Ω–∞–ª—å–Ω—ã–π learning rate
            'weight_decay': 0.0001, # –ú–µ–Ω—å—à–∏–π weight decay
            'momentum': 0.937,
            'warmup_epochs': 5,       # –ë–æ–ª—å—à–µ warmup —ç–ø–æ—Ö
            'warmup_momentum': 0.8,
            'warmup_bias_lr': 0.05,   # –ú–µ–Ω—å—à–∏–π bias lr

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —Å–ª–∏–ø–∞–Ω–∏—è –±–æ–∫—Å–æ–≤
            'box': 5.0,              # –í–µ—Å –±–æ–∫—Å–æ–≤
            'cls': 0.5,              # –í–µ—Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            'dfl': 1.5,              # Distribution Focal Loss
            'overlap_mask': False,   # –û—Ç–∫–ª—é—á–∞–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
            'mask_ratio': 1,
            'dropout': 0.1,          # Dropout –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
            'iou': 0.7,              # IoU threshold
            'conf': 0.25             # Confidence threshold
        }
        
        print("–ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è...")
        print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {train_args}")
        
        try:
            results = model.train(**train_args)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            best_model_path = self.model_output_dir / 'overfit_model' / 'weights' / 'best.pt'
            if best_model_path.exists():
                final_model_path = self.model_output_dir / 'best_overfit_model.pt'
                shutil.copy2(best_model_path, final_model_path)
                print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")
            
            return results
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            raise
    
    def validate_and_test(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        model_path = self.model_output_dir / 'best_overfit_model.pt'
        
        if not model_path.exists():
            print("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            return
        
        model = YOLO(model_path)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        print("–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")
        val_results = model.val(
            data=str(self.dataset_path / 'dataset.yaml'),
            device=self.device,
            conf=0.001,  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
            iou=0.6,
            save_json=True
        )
        
        print(f"mAP50: {val_results.box.map50:.4f}")
        print(f"mAP50-95: {val_results.box.map:.4f}")
        
        # –¢–µ—Å—Ç –Ω–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
        test_images = list((self.dataset_path / 'train' / 'images').glob('*.png'))
        print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {len(test_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö...")
        
        for i, img_path in enumerate(test_images[:5]):  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5
            results = model(str(img_path), conf=0.001, iou=0.6)
            
            output_path = self.model_output_dir / f'test_result_{i}.jpg'
            results[0].save(str(output_path))
            
            print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i}: {len(results[0].boxes) if results[0].boxes else 0} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π")
            
            if results[0].boxes:
                for box in results[0].boxes:
                    class_id = int(box.cls[0])
                    confidence = float(box.conf[0])
                    print(f"  –ö–ª–∞—Å—Å: {class_id}, –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    source_dir = "/home/rsim/itcamp2025/nakladnayaOCR/data/yolo_dataset"
    aug_dataset_dir = "/home/rsim/itcamp2025/nakladnayaOCR/yolo_training/augmented_dataset"
    model_output_dir = "/home/rsim/itcamp2025/nakladnayaOCR/yolo_training/overfit_models"
    
    print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    augmentator = DataAugmentator(source_dir, aug_dataset_dir)
    augmentator.create_augmented_dataset(num_augmentations=100)
    
    print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º...")
    trainer = EnhancedYoloTrainer(aug_dataset_dir, model_output_dir)
    results = trainer.train_overfit_model()
    
    print("\nüìä –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    trainer.validate_and_test()
    
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ! –ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –ø–æ–∫–∞–∑–∞—Ç—å –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö.")

if __name__ == "__main__":
    main()
